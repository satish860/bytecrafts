[
  {
    "title": "Hello world",
    "slug": "hello-world",
    "date": "1992-02-25T07:52:00.000Z",
    "content": "const{Fragment:e,jsx:t,jsxs:n}=arguments[0];function _createMdxContent(o){const r={p:\"p\",...o.components},{Callout:c}=r;return c||function(e,t){throw new Error(\"Expected \"+(t?\"component\":\"object\")+\" `\"+e+\"` to be defined: you likely forgot to import, pass, or provide it.\")}(\"Callout\",!0),n(e,{children:[t(c,{type:\"warning\",children:\"Hello I am a callout\"}),\"\\n\",t(r.p,{children:\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed non risus. Suspendisse\"})]})}return{default:function(e={}){const{wrapper:n}=e.components||{};return n?t(n,{...e,children:t(_createMdxContent,{...e})}):_createMdxContent(e)}};",
    "published": true,
    "description": "This is our first blog post. Really cool",
    "permalink": "/blog/hello-world"
  },
  {
    "title": "Cache Augmented Generation: An Innovative Alternative to Traditional RAG, But Still a Long Way to Go",
    "slug": "cache-augmented-generation",
    "date": "2025-01-20T03:30:00.000Z",
    "content": "const{Fragment:e,jsx:n,jsxs:l}=arguments[0];function _createMdxContent(a){const t={code:\"code\",figure:\"figure\",p:\"p\",pre:\"pre\",span:\"span\",...a.components};return l(e,{children:[n(t.p,{children:\"\\\"Don't do RAG, do CAG instead\\\" has been flooding Twitter and LinkedIn lately, and predictably, people started declaring RAG dead because of this. But here's the thing - Cache Augmented Generation (CAG) isn't some revolutionary new approach. It's been quietly powering the systems of major players like OpenAI and Anthropic for a while now, and Google was actually the pioneer in bringing caching back into the spotlight. Despite all the buzz, I found myself frustrated trying to find a straightforward implementation. The original paper's approach feels unnecessarily complex and doesn't scale well in practice. So I decided to build my own implementation, focusing on simplicity and practicality.\"}),\"\\n\",n(t.p,{children:\"Think about how your brain works when having a conversation. You don't recalculate everything you know about the topic each time you speak - you keep relevant information readily available in your working memory. That's essentially what KV caching does for language models.\"}),\"\\n\",n(t.p,{children:\"I built a simple system to show how this works, and I was surprised by how straightforward it was. Let's start with the basic setup:\"}),\"\\n\",n(t.figure,{\"data-rehype-pretty-code-figure\":\"\",children:n(t.pre,{style:{backgroundColor:\"#24292e\",color:\"#e1e4e8\"},tabIndex:\"0\",\"data-language\":\"python\",\"data-theme\":\"github-dark\",children:l(t.code,{\"data-language\":\"python\",\"data-theme\":\"github-dark\",style:{display:\"grid\"},children:[l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#F97583\"},children:\"from\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" transformers \"}),n(t.span,{style:{color:\"#F97583\"},children:\"import\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#F97583\"},children:\"from\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" transformers.cache_utils \"}),n(t.span,{style:{color:\"#F97583\"},children:\"import\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" DynamicCache\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#F97583\"},children:\"import\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" torch\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#6A737D\"},children:\"# Define model name\"})}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"model_name \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#9ECBFF\"},children:' \"meta-llama/Llama-3.2-1B-Instruct\"'})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#6A737D\"},children:\"# Load the tokenizer and model\"})}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"tokenizer \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" AutoTokenizer.from_pretrained(model_name)\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"model \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" AutoModelForCausalLM.from_pretrained(\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#E1E4E8\"},children:\"    model_name,\"})}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#FFAB70\"},children:\"    torch_dtype\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\"torch.float16,\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#FFAB70\"},children:\"    device_map\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#9ECBFF\"},children:'\"auto\"'}),n(t.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#E1E4E8\"},children:\")\"})})]})})}),\"\\n\",n(t.p,{children:\"Nothing fancy here - we're just loading a smaller version of Llama. I chose this model because it's like a compact car: it might not be as powerful as a Tesla, but it gets the job done and you can actually park it in your garage (or in this case, run it on your laptop).\"}),\"\\n\",n(t.p,{children:\"The real magic happens in how we process and store information:\"}),\"\\n\",n(t.figure,{\"data-rehype-pretty-code-figure\":\"\",children:n(t.pre,{style:{backgroundColor:\"#24292e\",color:\"#e1e4e8\"},tabIndex:\"0\",\"data-language\":\"python\",\"data-theme\":\"github-dark\",children:l(t.code,{\"data-language\":\"python\",\"data-theme\":\"github-dark\",style:{display:\"grid\"},children:[l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#F97583\"},children:\"def\"}),n(t.span,{style:{color:\"#B392F0\"},children:\" preprocess_knowledge\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\"(\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#E1E4E8\"},children:\"    model,\"})}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#E1E4E8\"},children:\"    tokenizer,\"})}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"    prompt: \"}),n(t.span,{style:{color:\"#79B8FF\"},children:\"str\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#E1E4E8\"},children:\") -> DynamicCache:\"})}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"    embed_device \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" model.model.embed_tokens.weight.device\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"    input_ids \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" tokenizer.encode(prompt, \"}),n(t.span,{style:{color:\"#FFAB70\"},children:\"return_tensors\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#9ECBFF\"},children:'\"pt\"'}),n(t.span,{style:{color:\"#E1E4E8\"},children:\").to(embed_device)\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"    past_key_values \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" DynamicCache()\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#F97583\"},children:\"    with\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" torch.no_grad():\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"        outputs \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" model(\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#FFAB70\"},children:\"            input_ids\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\"input_ids,\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#FFAB70\"},children:\"            past_key_values\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\"past_key_values,\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#FFAB70\"},children:\"            use_cache\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#79B8FF\"},children:\"True\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#FFAB70\"},children:\"            output_attentions\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#79B8FF\"},children:\"False\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#FFAB70\"},children:\"            output_hidden_states\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#79B8FF\"},children:\"False\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#E1E4E8\"},children:\"        )\"})}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#F97583\"},children:\"    return\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" outputs.past_key_values\"})]})]})})}),\"\\n\",n(t.p,{children:\"This function is like creating a cheat sheet before an exam - it processes the information once and keeps the important bits readily available. The neat part is that we're not doing anything particularly complex; we're just being smart about storing what we've already calculated.\"}),\"\\n\",n(t.p,{children:\"And here's how we use that stored information:\"}),\"\\n\",n(t.figure,{\"data-rehype-pretty-code-figure\":\"\",children:n(t.pre,{style:{backgroundColor:\"#24292e\",color:\"#e1e4e8\"},tabIndex:\"0\",\"data-language\":\"python\",\"data-theme\":\"github-dark\",children:l(t.code,{\"data-language\":\"python\",\"data-theme\":\"github-dark\",style:{display:\"grid\"},children:[l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#F97583\"},children:\"def\"}),n(t.span,{style:{color:\"#B392F0\"},children:\" generate\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\"(\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#E1E4E8\"},children:\"    model,\"})}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#E1E4E8\"},children:\"    input_ids: torch.Tensor,\"})}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#E1E4E8\"},children:\"    past_key_values,\"})}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"    max_new_tokens: \"}),n(t.span,{style:{color:\"#79B8FF\"},children:\"int\"}),n(t.span,{style:{color:\"#F97583\"},children:\" =\"}),n(t.span,{style:{color:\"#79B8FF\"},children:\" 3000\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#E1E4E8\"},children:\") -> torch.Tensor:\"})}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"    embed_device \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" model.model.embed_tokens.weight.device\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"    origin_ids \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" input_ids\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"    input_ids \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" input_ids.to(embed_device)\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"    output_ids \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" input_ids.clone()\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"    next_token \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" input_ids\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#F97583\"},children:\"    with\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" torch.no_grad():\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#F97583\"},children:\"        for\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" _ \"}),n(t.span,{style:{color:\"#F97583\"},children:\"in\"}),n(t.span,{style:{color:\"#79B8FF\"},children:\" range\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\"(max_new_tokens):\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"            outputs \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" model(\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#FFAB70\"},children:\"                input_ids\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\"next_token,\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#FFAB70\"},children:\"                past_key_values\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\"past_key_values,\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#FFAB70\"},children:\"                use_cache\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#79B8FF\"},children:\"True\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#E1E4E8\"},children:\"            )\"})}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"            next_token_logits \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" outputs.logits[:, \"}),n(t.span,{style:{color:\"#F97583\"},children:\"-\"}),n(t.span,{style:{color:\"#79B8FF\"},children:\"1\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\", :]\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"            next_token \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" next_token_logits.argmax(\"}),n(t.span,{style:{color:\"#FFAB70\"},children:\"dim\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=-\"}),n(t.span,{style:{color:\"#79B8FF\"},children:\"1\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\").unsqueeze(\"}),n(t.span,{style:{color:\"#F97583\"},children:\"-\"}),n(t.span,{style:{color:\"#79B8FF\"},children:\"1\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"            next_token \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" next_token.to(embed_device)\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"            past_key_values \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" outputs.past_key_values\"})]}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#E1E4E8\"},children:\"            output_ids \"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" torch.cat([output_ids, next_token], \"}),n(t.span,{style:{color:\"#FFAB70\"},children:\"dim\"}),n(t.span,{style:{color:\"#F97583\"},children:\"=\"}),n(t.span,{style:{color:\"#79B8FF\"},children:\"1\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#F97583\"},children:\"            if\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" next_token.item() \"}),n(t.span,{style:{color:\"#F97583\"},children:\"in\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" model.config.eos_token_id:\"})]}),\"\\n\",n(t.span,{\"data-line\":\"\",children:n(t.span,{style:{color:\"#F97583\"},children:\"                break\"})}),\"\\n\",l(t.span,{\"data-line\":\"\",children:[n(t.span,{style:{color:\"#F97583\"},children:\"    return\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\" output_ids[:, origin_ids.shape[\"}),n(t.span,{style:{color:\"#F97583\"},children:\"-\"}),n(t.span,{style:{color:\"#79B8FF\"},children:\"1\"}),n(t.span,{style:{color:\"#E1E4E8\"},children:\"]:]\"})]})]})})}),\"\\n\",n(t.p,{children:\"Now, there's a catch - and it's a pretty significant one. This approach only works well with relatively small amounts of text - about 60 pages worth. That might sound like a lot, but in the world of enterprise document processing, it's tiny. It's like having a really efficient filing system that can only handle one drawer's worth of documents.\"}),\"\\n\",n(t.p,{children:\"But here's the interesting part: this limitation might not matter for many real-world applications. Take customer support, for instance. When someone contacts support, they usually have a specific problem about a specific product. You don't need the entire company knowledge base in memory - just the relevant parts about that product.\"}),\"\\n\",n(t.p,{children:\"I've seen this pattern before: sometimes constraints force you to be smarter about how you solve problems. Instead of trying to load everything into memory, you get better at picking what's relevant. It's like the difference between memorizing an entire textbook and just knowing which chapter to reference.\"}),\"\\n\",n(t.p,{children:\"This approach really shines in situations where you need quick, focused responses based on a manageable amount of context. Think of it as having a really knowledgeable assistant who's great at handling one topic at a time, rather than trying to be an expert on everything simultaneously.\"}),\"\\n\",n(t.p,{children:\"For small businesses or specific departments within larger organizations, this could be exactly what they need. It's not going to replace huge enterprise systems, but it might be perfect for that customer service team helping people troubleshoot their coffee makers, or that internal documentation system where people look up company policies.\"}),\"\\n\",n(t.p,{children:\"The key insight here isn't just about the technical implementation - it's about recognizing that sometimes, working within constraints leads to more practical solutions. You might not be able to process your entire document database at once, but do you really need to?\"})]})}return{default:function(e={}){const{wrapper:l}=e.components||{};return l?n(l,{...e,children:n(_createMdxContent,{...e})}):_createMdxContent(e)}};",
    "published": true,
    "description": "Cache Augmented Generation can be future If LLMs are small and fast.",
    "permalink": "/blog/cache-augmented-generation"
  },
  {
    "title": "Beyond Reterival: How Reasoning Models Can Reshape Research",
    "slug": "beyond-reterival",
    "date": "2025-01-30T03:30:00.000Z",
    "content": "const{Fragment:e,jsx:n,jsxs:l}=arguments[0];function _createMdxContent(r){const s={a:\"a\",code:\"code\",figure:\"figure\",h2:\"h2\",h3:\"h3\",hr:\"hr\",li:\"li\",p:\"p\",pre:\"pre\",span:\"span\",strong:\"strong\",ul:\"ul\",...r.components};return l(e,{children:[l(s.p,{children:[\"In the rapidly evolving landscape of AI applications, one challenge remains particularly complex: conducting thorough, well-structured research at scale. Traditional research methods often fall short when dealing with vast amounts of information, maintaining consistency, and ensuring comprehensive coverage of topics. Today, I'm excited to share our approach to solving this problem using a coordinated system of Large Language Models (LLMs), enhanced with \",n(s.strong,{children:\"DeepSeek Reasoner\"}),\" to improve logical coherence and research depth.\"]}),\"\\n\",n(s.h2,{id:\"the-role-of-reasoning-models-in-research\",children:n(s.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#the-role-of-reasoning-models-in-research\",children:n(s.strong,{children:\"The Role of Reasoning Models in Research\"})})}),\"\\n\",n(s.p,{children:\"Anyone who has conducted extensive research knows the challenges:\"}),\"\\n\",l(s.ul,{children:[\"\\n\",l(s.li,{children:[n(s.strong,{children:\"Information overload\"}),\" and difficulty in maintaining focus\"]}),\"\\n\",l(s.li,{children:[n(s.strong,{children:\"Inconsistent methodology\"}),\" across different research topics\"]}),\"\\n\",l(s.li,{children:[n(s.strong,{children:\"Limited ability to retain context\"}),\" across multiple subtopics\"]}),\"\\n\",l(s.li,{children:[n(s.strong,{children:\"Time-consuming manual synthesis\"}),\" of information\"]}),\"\\n\",n(s.li,{children:n(s.strong,{children:\"Difficulty in maintaining citations and source tracking\"})}),\"\\n\"]}),\"\\n\",l(s.p,{children:[\"Addressing these challenges requires more than just language models retrieving information; it necessitates \",n(s.strong,{children:\"reasoning models\"}),\" that can analyze, synthesize, and refine research dynamically. Reasoning models enhance LLM-based research by maintaining \",n(s.strong,{children:\"logical coherence, identifying inconsistencies, and refining outputs through iterative improvements\"}),\".\"]}),\"\\n\",n(s.hr,{}),\"\\n\",n(s.h2,{id:\"a-reasoning-driven-multi-llm-architecture\",children:n(s.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#a-reasoning-driven-multi-llm-architecture\",children:n(s.strong,{children:\"A Reasoning-Driven Multi-LLM Architecture\"})})}),\"\\n\",l(s.p,{children:[\"Our solution implements a \",n(s.strong,{children:\"three-tier architecture\"}),\", where each tier is handled by a specialized LLM:\"]}),\"\\n\",n(s.h3,{id:\"1-the-planner-deepseek\",children:n(s.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#1-the-planner-deepseek\",children:n(s.strong,{children:\"1. The Planner (DeepSeek)\"})})}),\"\\n\",n(s.p,{children:\"Think of this as your research project manager. When given a research question, it:\"}),\"\\n\",l(s.ul,{children:[\"\\n\",n(s.li,{children:\"Analyzes the complexity of the topic\"}),\"\\n\",n(s.li,{children:\"Breaks down the research into manageable subtasks\"}),\"\\n\",n(s.li,{children:\"Creates a structured execution plan\"}),\"\\n\",n(s.li,{children:\"Defines clear success criteria for each step\"}),\"\\n\"]}),\"\\n\",n(s.p,{children:\"Here’s how the planner generates a structured research plan using DeepSeek:\"}),\"\\n\",n(s.figure,{\"data-rehype-pretty-code-figure\":\"\",children:n(s.pre,{style:{backgroundColor:\"#24292e\",color:\"#e1e4e8\"},tabIndex:\"0\",\"data-language\":\"python\",\"data-theme\":\"github-dark\",children:l(s.code,{\"data-language\":\"python\",\"data-theme\":\"github-dark\",style:{display:\"grid\"},children:[l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"def\"}),n(s.span,{style:{color:\"#B392F0\"},children:\" call_planner\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(scenario):\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    deepseek_prompt \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:' \"\"\"You are an AI research planner. Your task is to break down a given research scenario into structured steps, ensuring logical flow and completeness.\"\"\"'})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    prompt \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#F97583\"},children:\" f\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"\"\"'})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"    {\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"deepseek_prompt\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"}\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#9ECBFF\"},children:\"    \"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#9ECBFF\"},children:\"    Scenario:\"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"    {\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"scenario\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"}\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#9ECBFF\"},children:\"    \"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#9ECBFF\"},children:\"    Please provide the next steps in your plan.\"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#9ECBFF\"},children:'    \"\"\"'})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    client \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" OpenAI(\"}),n(s.span,{style:{color:\"#FFAB70\"},children:\"api_key\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"os.environ[\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"DEEPSEEK_API_KEY\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"], \"}),n(s.span,{style:{color:\"#FFAB70\"},children:\"base_url\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"https://api.deepseek.com\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    response \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" client.chat.completions.create(\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"        model\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"deepseek-reasoner\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"        messages\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"[{\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:\"'role'\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:\"'user'\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\", \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:\"'content'\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": prompt}],\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    )\"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    plan \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" response.choices[\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"0\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"].message.content\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"    return\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" plan\"})]})]})})}),\"\\n\",n(s.hr,{}),\"\\n\",n(s.h3,{id:\"2-the-executor-claude\",children:n(s.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#2-the-executor-claude\",children:n(s.strong,{children:\"2. The Executor (Claude)\"})})}),\"\\n\",n(s.p,{children:\"This is your primary researcher, responsible for:\"}),\"\\n\",l(s.ul,{children:[\"\\n\",n(s.li,{children:\"Following the research plan step by step\"}),\"\\n\",n(s.li,{children:\"Managing interactions with various research tools\"}),\"\\n\",n(s.li,{children:\"Synthesizing information from multiple sources\"}),\"\\n\",n(s.li,{children:\"Maintaining research coherence\"}),\"\\n\"]}),\"\\n\",n(s.figure,{\"data-rehype-pretty-code-figure\":\"\",children:n(s.pre,{style:{backgroundColor:\"#24292e\",color:\"#e1e4e8\"},tabIndex:\"0\",\"data-language\":\"python\",\"data-theme\":\"github-dark\",children:l(s.code,{\"data-language\":\"python\",\"data-theme\":\"github-dark\",style:{display:\"grid\"},children:[n(s.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"def\"}),n(s.span,{style:{color:\"#B392F0\"},children:\" plan_execute\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(message_list, plan):\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    messages \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" [\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"        {\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:\"'role'\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:\"'user'\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\", \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:\"'content'\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": plan}\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    ]\"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    response \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" anthropic_client.messages.create(\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"        model\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"claude-3-5-haiku-20241022\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"        max_tokens\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"1024\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"        system\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"claude_system_prompt,\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"        tools\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"TOOLS\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"        messages\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"messages\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    )\"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    messages.append({\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"role\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"assistant\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\", \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"content\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": response.content})\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    final_answer \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:' \"\"'})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\" \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"    while\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" response.stop_reason \"}),n(s.span,{style:{color:\"#F97583\"},children:\"==\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:' \"tool_use\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\":\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"        if\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" response.content \"}),n(s.span,{style:{color:\"#F97583\"},children:\"and\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\" len\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(response.content) \"}),n(s.span,{style:{color:\"#F97583\"},children:\">\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\" 0\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\":\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"            text_block \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" response.content[\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"0\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"]\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"            if\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\" hasattr\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(text_block, \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:\"'text'\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\") \"}),n(s.span,{style:{color:\"#F97583\"},children:\"and\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" text_block.text:\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"                print\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"'}),n(s.span,{style:{color:\"#79B8FF\"},children:\"\\\\n\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'Model Response:\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\", text_block.text)\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"            print\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"-\"'}),n(s.span,{style:{color:\"#F97583\"},children:\" *\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\" 80\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"        tool \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" response.content[\"}),n(s.span,{style:{color:\"#F97583\"},children:\"-\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"1\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"]\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"        print\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"'}),n(s.span,{style:{color:\"#79B8FF\"},children:\"\\\\n\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'Calling Tool:\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\", tool.name)\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"        print\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"-\"'}),n(s.span,{style:{color:\"#F97583\"},children:\" *\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\" 80\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"        if\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" (tool.name \"}),n(s.span,{style:{color:\"#F97583\"},children:\"and\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" tool.name \"}),n(s.span,{style:{color:\"#F97583\"},children:\"==\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:\" 'instructions_complete'\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"):\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"            final_answer \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" tool.input\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"            print\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"'}),n(s.span,{style:{color:\"#79B8FF\"},children:\"\\\\n\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\", final_answer)\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"            print\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"-\"'}),n(s.span,{style:{color:\"#F97583\"},children:\" *\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\" 80\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#F97583\"},children:\"            break\"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"        if\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" tool.name \"}),n(s.span,{style:{color:\"#F97583\"},children:\"in\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" function_mapping:\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"            input_arguments_str \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" tool.input\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"            print\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"'}),n(s.span,{style:{color:\"#79B8FF\"},children:\"\\\\n\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'Input Arguments:\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\", input_arguments_str)\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"            print\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"-\"'}),n(s.span,{style:{color:\"#F97583\"},children:\" *\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\" 80\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"            res \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" function_mapping[tool.name](\"}),n(s.span,{style:{color:\"#F97583\"},children:\"**\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"input_arguments_str)\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"            print\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"'}),n(s.span,{style:{color:\"#79B8FF\"},children:\"\\\\n\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'Tool Response:\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\", res)\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#79B8FF\"},children:\"            print\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"-\"'}),n(s.span,{style:{color:\"#F97583\"},children:\" *\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\" 80\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"        else\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\":\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"            raise\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\" ValueError\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(\"}),n(s.span,{style:{color:\"#F97583\"},children:\"f\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"Unknown tool: '}),n(s.span,{style:{color:\"#79B8FF\"},children:\"{\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"tool.name\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"}\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"            \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"        messages.append({\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"role\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"user\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\", \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"content\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": [{\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#9ECBFF\"},children:'            \"type\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"tool_result\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#9ECBFF\"},children:'            \"tool_use_id\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": tool.id,\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#9ECBFF\"},children:'            \"content\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": res\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"        }]})\"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"        response \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" anthropic_client.messages.create(\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"            model\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"claude-3-5-haiku-20241022\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"            max_tokens\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"1024\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"            system\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"claude_system_prompt,\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"            tools\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"TOOLS\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"            messages\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"messages\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"        )\"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"        messages.append({\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"role\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"assistant\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\", \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"content\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": response.content})\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"    return\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" messages\"})]})]})})}),\"\\n\",n(s.p,{children:\"The executor implements a Claude-based tool execution loop that follows the instructions outlined in the research plan until the end goal is achieved. This process ensures that each step of the research is methodically completed while dynamically adapting to any unexpected challenges. The execution loop involves parsing the research plan into discrete, actionable tasks, iteratively calling the appropriate tools and APIs, and refining responses through multiple iterations to improve accuracy. Additionally, it maintains dependencies between sub-tasks to ensure logical flow.\"}),\"\\n\",n(s.p,{children:\"By leveraging Claude's reasoning capabilities, the executor not only maintains context but also evaluates the reliability of retrieved information, discerns contradictory findings, and applies logical deductions to refine the research output. This approach ensures that the research process is not just a linear retrieval pipeline but a reasoning-driven system that enhances depth and accuracy. This iterative execution framework ensures that research is both structured and flexible, optimizing efficiency and coherence.\"}),\"\\n\",n(s.p,{children:\"You can improve this simple loop to perform any complex task. OpenAI Operator, Claude computer and any new Agent framework is a simple loop operation.\"}),\"\\n\",n(s.hr,{}),\"\\n\",n(s.h3,{id:\"3-the-information-retriever-perplexity-ai\",children:n(s.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#3-the-information-retriever-perplexity-ai\",children:n(s.strong,{children:\"3. The Information Retriever (Perplexity AI)\"})})}),\"\\n\",n(s.p,{children:\"This tool is provided to the executor to enhance research capabilities. It assists in performing targeted web searches, extracting relevant information, maintaining proper citation tracking, and ensuring information accuracy. By integrating directly with the executor's workflow, it ensures that research remains well-sourced, up-to-date, and contextually relevant.\"}),\"\\n\",n(s.figure,{\"data-rehype-pretty-code-figure\":\"\",children:n(s.pre,{style:{backgroundColor:\"#24292e\",color:\"#e1e4e8\"},tabIndex:\"0\",\"data-language\":\"python\",\"data-theme\":\"github-dark\",children:l(s.code,{\"data-language\":\"python\",\"data-theme\":\"github-dark\",style:{display:\"grid\"},children:[l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"def\"}),n(s.span,{style:{color:\"#B392F0\"},children:\" search_web\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(query):\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    client \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" OpenAI(\"}),n(s.span,{style:{color:\"#FFAB70\"},children:\"api_key\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"os.environ[\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"PERPLEXITYAI_API_KEY\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"], \"}),n(s.span,{style:{color:\"#FFAB70\"},children:\"base_url\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"https://api.perplexity.ai\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    messages \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" [\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"        {\"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#9ECBFF\"},children:'            \"role\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"system\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#9ECBFF\"},children:'            \"content\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"You are an artificial intelligence assistant and you need to answer like a Data collection engine with as much information as possible.\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"        },\"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"        {   \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#9ECBFF\"},children:'            \"role\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": \"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"user\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#9ECBFF\"},children:'            \"content\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\": query,\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"        },\"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    ]\"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:\" \"}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"    response \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" client.chat.completions.create(\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"        model\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"sonar\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"        messages\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"messages,\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    )\"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"    \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"    try\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\":\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"        response \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" client.chat.completions.create(\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"            model\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"sonar\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\",\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#FFAB70\"},children:\"            messages\"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"messages,\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"        )\"})}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"        \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"        if\"}),n(s.span,{style:{color:\"#F97583\"},children:\" not\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" response.choices:\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"            logger.error(\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"No response choices available\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"            return\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:' \"Error: No response received from the search\"'})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"            \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"        content \"}),n(s.span,{style:{color:\"#F97583\"},children:\"=\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" response.choices[\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"0\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"].message.content\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"        return\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" content\"})]}),\"\\n\",n(s.span,{\"data-line\":\"\",children:n(s.span,{style:{color:\"#E1E4E8\"},children:\"        \"})}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"    except\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\" Exception\"}),n(s.span,{style:{color:\"#F97583\"},children:\" as\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\" e:\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#E1E4E8\"},children:\"        logger.error(\"}),n(s.span,{style:{color:\"#F97583\"},children:\"f\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"Error during web search: '}),n(s.span,{style:{color:\"#79B8FF\"},children:\"{str\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(e)\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"}\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"'}),n(s.span,{style:{color:\"#E1E4E8\"},children:\")\"})]}),\"\\n\",l(s.span,{\"data-line\":\"\",children:[n(s.span,{style:{color:\"#F97583\"},children:\"        return\"}),n(s.span,{style:{color:\"#F97583\"},children:\" f\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"Error during search: '}),n(s.span,{style:{color:\"#79B8FF\"},children:\"{str\"}),n(s.span,{style:{color:\"#E1E4E8\"},children:\"(e)\"}),n(s.span,{style:{color:\"#79B8FF\"},children:\"}\"}),n(s.span,{style:{color:\"#9ECBFF\"},children:'\"'})]})]})})}),\"\\n\",n(s.h2,{id:\"you-should-be-able-to-replace-the-web-search-tool-with-any-tool-you-can-think-ofexaaitavily-and-others-too-dont-bog-down-on-perplexity\",children:n(s.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#you-should-be-able-to-replace-the-web-search-tool-with-any-tool-you-can-think-ofexaaitavily-and-others-too-dont-bog-down-on-perplexity\",children:\"You should be able to replace the web search tool with any tool you can think of.Exa.ai,Tavily and others too. Dont bog down on Perplexity.\"})}),\"\\n\",n(s.h2,{id:\"future-enhancements\",children:n(s.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#future-enhancements\",children:n(s.strong,{children:\"Future Enhancements\"})})}),\"\\n\",n(s.p,{children:\"To further improve our system, we are focusing on:\"}),\"\\n\",l(s.ul,{children:[\"\\n\",l(s.li,{children:[n(s.strong,{children:\"Automated fact-checking\"}),\" to enhance research reliability. Rather than relying solely on web search, We should restrict to trusted sources only.\"]}),\"\\n\",l(s.li,{children:[n(s.strong,{children:\"Improved context retention\"}),\" using vector databases or Graph based Memory like Zep\"]}),\"\\n\",l(s.li,{children:[n(s.strong,{children:\"Fine-tuned LLMs\"}),\" for domain-specific research. We will do a distillation of Anthropic's Claude to create our own LLM for research. Cost benefit.\"]}),\"\\n\",l(s.li,{children:[n(s.strong,{children:\"Enhanced RAG capabilities\"}),\" to handle more complex queries also bring your own data rather than relying on web search\"]}),\"\\n\"]}),\"\\n\",l(s.p,{children:[\"We are also integrating \",n(s.a,{href:\"https://github.com/stanford-oval/storm\",children:n(s.strong,{children:\"Storm\"})}),\" and \",n(s.a,{href:\"https://github.com/zjunlp/OmniThink\",children:n(s.strong,{children:\"Omnithink\"})}),\"—two frameworks that refine LLM research through structured reasoning and advanced knowledge retrieval. Storm focuses on multi-agent orchestration and dynamic knowledge retrieval, while Omnithink enhances logical inference and structured reasoning in LLMs. By leveraging these improvements, we aim to make AI-driven research more \",n(s.strong,{children:\"scalable, structured, and insightful\"}),\".\"]}),\"\\n\",n(s.hr,{}),\"\\n\",n(s.h2,{id:\"conclusion\",children:n(s.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#conclusion\",children:n(s.strong,{children:\"Conclusion\"})})}),\"\\n\",l(s.p,{children:[\"Using a reasoning-driven LLM architecture, we enhance the way research is conducted at scale. By breaking down complex queries into structured tasks, \",n(s.strong,{children:\"applying logical reasoning\"}),\", and leveraging \",n(s.strong,{children:\"automated research tools\"}),\", we improve research depth, coherence, and efficiency.\"]}),\"\\n\",l(s.p,{children:[\"This is just the beginning. With advancements in \",n(s.strong,{children:\"LLMs, reasoning models, and RAG\"}),\", we are continually refining our approach to \",n(s.strong,{children:\"AI-driven research\"}),\".\"]}),\"\\n\",l(s.p,{children:[\"For access to the complete code, visit the GitHub Gist: \",n(s.a,{href:\"https://gist.github.com/apprakash/0cb10d780e61dcd75e42d722bfa6bd3f\",children:\"Full Code Implementation\"})]})]})}return{default:function(e={}){const{wrapper:l}=e.components||{};return l?n(l,{...e,children:n(_createMdxContent,{...e})}):_createMdxContent(e)}};",
    "published": true,
    "description": "Reasoning models are not your chat but a better research Planner and it can be a Top-Notch research Executors too.",
    "permalink": "/blog/beyond-reterival"
  },
  {
    "title": "Build Your Own Agent Framework - Step by Step",
    "slug": "build-your-own-agent-framework-step-by-step",
    "date": "2024-11-14T03:30:00.000Z",
    "content": "const{Fragment:e,jsx:n,jsxs:t}=arguments[0];function _createMdxContent(r){const o={a:\"a\",blockquote:\"blockquote\",code:\"code\",h1:\"h1\",h3:\"h3\",h4:\"h4\",p:\"p\",pre:\"pre\",strong:\"strong\",...r.components};return t(e,{children:[n(o.p,{children:\"Best way to learn is by doing. So lets our build our own Agent Framework like OpenAI Swarm. Well we need to start small.\"}),\"\\n\",t(o.blockquote,{children:[\"\\n\",n(o.h4,{id:\"pre-requisites\",children:n(o.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#pre-requisites\",children:\"Pre-requisites\"})}),\"\\n\"]}),\"\\n\",t(o.blockquote,{children:[\"\\n\",n(o.h4,{id:\"i-assume-you-have-some-knowledge-of-python-and-used-a-openai-api-if-not-you-can-follow-the-getting-started-guide\",children:t(o.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#i-assume-you-have-some-knowledge-of-python-and-used-a-openai-api-if-not-you-can-follow-the-getting-started-guide\",children:[\"I assume you have some knowledge of Python and used a OpenAI API. If not you can follow the \",n(o.a,{href:\"https://platform.openai.com/docs/api-reference/introduction\",children:\"Getting Started Guide\"})]})}),\"\\n\"]}),\"\\n\",n(o.p,{children:\"Now that the pre-requisites are out of the way, we can start building our own Agent Framework.\"}),\"\\n\",n(o.h3,{id:\"so-what-is-a-agent-\",children:n(o.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#so-what-is-a-agent-\",children:\"So What is a Agent ?\"})}),\"\\n\",n(o.p,{children:\"My own take is the Agents are something which can take an input, perform some task and return a output. Simple as that. If you want to get the latest news from the web, LLM doesnt have the capability to do that. But a agent can browse the web, read the news and then tell you the latest news.\"}),\"\\n\",t(o.blockquote,{children:[\"\\n\",n(o.p,{children:\"Yes there is many other definitions of Agent, but for now lets stick with my definition for making a framework. We will talk about memory and other things in later posts.\"}),\"\\n\"]}),\"\\n\",n(o.p,{children:\"So how can you build a Agent. Well there are many ways to do that. But the most popular way is to use LLMs with function calling capabilities.\"}),\"\\n\",n(o.h1,{id:\"function-calling\",children:n(o.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#function-calling\",children:\"Function Calling\"})}),\"\\n\",n(o.p,{children:\"LLMs a Passive responders, You ask a question and they respond. But with function calling capabilities, you can ask it to respond if it knows the answer else ask it to use the tools like web search, database lookup, etc. Then it can use the tools to get the answer and then return the answer.\"}),\"\\n\",n(o.p,{children:\"Rather than explaining the theory, lets jump into the code.\"}),\"\\n\",n(o.pre,{children:n(o.code,{children:\"! pip install openai \\n\"})}),\"\\n\",t(o.p,{children:[\"Now we need to setup the OpenAI API key. You can get your API key from \",n(o.a,{href:\"https://platform.openai.com/api-keys\",children:\"here\"})]}),\"\\n\",n(o.pre,{children:n(o.code,{children:'import openai\\r\\n\\r\\nopenai.api_key = \"sk-proj-your-openai-api-key\"\\n'})}),\"\\n\",t(o.p,{children:[\"Now we need to create a function calling agent with defining a simple function which can search the web. You can use any API to search the web. I am using \",n(o.a,{href:\"https://ydc-index.io/\",children:\"YDC-Index\"}),\" for this example. Its You.com search API.\"]}),\"\\n\",n(o.pre,{children:n(o.code,{children:'import requests\\r\\n\\r\\ndef get_ai_snippets_for_query(query):\\r\\n    headers = {\"X-API-Key\": \"your-api-key\"}\\r\\n    params = {\"query\": query}\\r\\n    return requests.get(\\r\\n        f\"https://api.ydc-index.io/search?query={query}\",\\r\\n        params=params,\\r\\n        headers=headers,\\r\\n    ).json()\\r\\nresults = get_ai_snippets_for_query(\"What is the latest news in india\")\\r\\nprint(results)\\r\\n\\n'})}),\"\\n\",n(o.p,{children:\"Now we need to introduce this function to LLM. But how can we do that, Well you need to convert the function into a string and then pass it to LLM. So let me define a function to convert the function into a string.\"}),\"\\n\",n(o.pre,{children:n(o.code,{children:'import inspect\\r\\n\\r\\ndef function_to_json(func) -> dict:\\r\\n    \"\"\"\\r\\n    Converts a Python function into a JSON-serializable dictionary\\r\\n    that describes the function\\'s signature, including its name,\\r\\n    description, and parameters.\\r\\n\\r\\n    Args:\\r\\n        func: The function to be converted.\\r\\n\\r\\n    Returns:\\r\\n        A dictionary representing the function\\'s signature in JSON format.\\r\\n    \"\"\"\\r\\n    type_map = {\\r\\n        str: \"string\",\\r\\n        int: \"integer\",\\r\\n        float: \"number\",\\r\\n        bool: \"boolean\",\\r\\n        list: \"array\",\\r\\n        dict: \"object\",\\r\\n        type(None): \"null\",\\r\\n    }\\r\\n\\r\\n    try:\\r\\n        signature = inspect.signature(func)\\r\\n    except ValueError as e:\\r\\n        raise ValueError(\\r\\n            f\"Failed to get signature for function {func.__name__}: {str(e)}\"\\r\\n        )\\r\\n\\r\\n    parameters = {}\\r\\n    for param in signature.parameters.values():\\r\\n        try:\\r\\n            param_type = type_map.get(param.annotation, \"string\")\\r\\n        except KeyError as e:\\r\\n            raise KeyError(\\r\\n                f\"Unknown type annotation {param.annotation} for parameter {param.name}: {str(e)}\"\\r\\n            )\\r\\n        parameters[param.name] = {\"type\": param_type}\\r\\n\\r\\n    required = [\\r\\n        param.name\\r\\n        for param in signature.parameters.values()\\r\\n        if param.default == inspect._empty\\r\\n    ]\\r\\n\\r\\n    return {\\r\\n        \"type\": \"function\",\\r\\n        \"function\": {\\r\\n            \"name\": func.__name__,\\r\\n            \"description\": func.__doc__ or \"\",\\r\\n            \"parameters\": {\\r\\n                \"type\": \"object\",\\r\\n                \"properties\": parameters,\\r\\n                \"required\": required,\\r\\n            },\\r\\n        },\\r\\n    }\\n'})}),\"\\n\",n(o.p,{children:\"This utility can take any arbitrary function and convert it into a JSON Schema which can be used by LLM to call the function.\"}),\"\\n\",n(o.p,{children:\"Now we need to call this function to LLM.\"}),\"\\n\",n(o.pre,{children:n(o.code,{children:\"websearch_tool = function_to_json(get_ai_snippets_for_query)\\n\"})}),\"\\n\",n(o.p,{children:\"Now we need to create a system prompt and then call the LLM with the history and the tools.\"}),\"\\n\",n(o.pre,{children:n(o.code,{children:'import json\\r\\n\\r\\n\\r\\nSYSTEM_PROMPT = \"\"\"\\r\\nYou are a helpful assistant that can answer questions and help with tasks. If you need any information from the internet, you can use the tools provided to you.\\r\\n\"\"\"\\r\\n\\r\\nhistory = []\\r\\nhistory.append({\"role\": \"system\", \"content\": SYSTEM_PROMPT})\\r\\nhistory.append({\"role\": \"user\", \"content\": \"What is the Latest news about Supreme court of india?\"})\\r\\n\\r\\nresponse = openai.chat.completions.create(\\r\\n    model=\"gpt-4o-mini\",\\r\\n    messages=history,\\r\\n    tools=[websearch_tool]\\r\\n)\\r\\n\\r\\nmessage = response.choices[0].message\\r\\n\\r\\nprint(message.model_dump_json())\\r\\nhistory.append(json.loads(message.model_dump_json()))\\n'})}),\"\\n\",n(o.p,{children:n(o.strong,{children:\"Output:\"})}),\"\\n\",t(o.p,{children:[\"Note the \",n(o.code,{children:\"tool_calls\"}),\" key in the response. This is the tool call which we need to use to call the function.\"]}),\"\\n\",n(o.pre,{children:n(o.code,{children:'{\"content\":null,\"refusal\":null,\"role\":\"assistant\",\"audio\":null,\"function_call\":null,\"tool_calls\":[{\"id\":\"call_TQQ8Md20X9BJvSywhLvlAUTB\",\"function\":{\"arguments\":\"{\\\\\"query\\\\\":\\\\\"Latest news Supreme Court of India\\\\\"}\",\"name\":\"get_ai_snippets_for_query\"},\"type\":\"function\"}]}\\n'})}),\"\\n\",t(o.p,{children:[\"It contains the \",n(o.code,{children:\"id\"}),\" of the tool call and the \",n(o.code,{children:\"function\"}),\" which needs to be called. In this case I asked the LLM to provide a Latest news which in turn will make the LLM think and then call the \",n(o.code,{children:\"get_ai_snippets_for_query\"}),\" function with the query as \",n(o.code,{children:\"Latest news Supreme Court of India\"}),\".\"]}),\"\\n\",n(o.p,{children:\"Now we need to call the function with the tool call id and the arguments.\"}),\"\\n\",n(o.pre,{children:n(o.code,{children:'for tools in message.tool_calls:\\r\\n    args = json.loads(tools.function.arguments)\\r\\n    raw_result = get_ai_snippets_for_query(**args)\\r\\n    history.append({\"role\": \"tool\", \"tool_call_id\": tools.id,\"tool_name\":tools.function.name, \"content\": raw_result})\\r\\n\\n'})}),\"\\n\",n(o.p,{children:\"Now that we have the result from the tool, we need to append it to the history and then call the LLM again to get the final answer.\"}),\"\\n\",n(o.pre,{children:n(o.code,{children:'function_response = openai.chat.completions.create(\\r\\n    model=\"gpt-4o-mini\",\\r\\n    messages=history,\\r\\n)\\r\\n\\r\\nprint(function_response.choices[0].message.content)\\r\\n\\n'})}),\"\\n\",n(o.p,{children:n(o.strong,{children:\"Output:\"})}),\"\\n\",n(o.pre,{children:n(o.code,{children:\"Here are some of the latest developments and news regarding the Supreme Court of India:\\r\\n\\r\\n1. **Child Pornography Ruling**: The Supreme Court ruled that merely possessing child pornographic material constitutes a criminal offence. This decision underscores legal culpability for preparatory actions related to inchoate crimes.\\r\\n\\r\\n2. **Caste-Based Discrimination Ban**: A significant verdict from the Supreme Court has banned caste-based discrimination, specifically prohibiting practices such as the division of manual labor and segregation of prisoners belonging to de-notified tribes.\\r\\n\\r\\n3. **YouTube Channel Hack**: The Supreme Court's official YouTube channel was compromised, displaying unauthorized content instead of the usual court hearing live streams. YouTube has since acted to remove the hacked content.\\r\\n\\r\\n4. **Maternity Benefits Inquiry**: The Supreme Court has questioned why maternity benefits are only available to adoptive mothers if the adopted child is under three months old, seeking clarity from the Centre on this policy.\\r\\n\\r\\n5. **Stakeholders Consultation on Disabilities**: The Supreme Court announced a two-day National Annual Stakeholders Consultation focusing on the rights of children living with disabilities, set to take place on September 28-29, 2024.\\r\\n\\r\\n6. **Emissions Standards Compliance**: The Air Quality Panel has indicated to the Supreme Court that states need to comply with emissions standards in order to address pollution issues effectively.\\r\\n\\r\\nThese updates highlight ongoing legal and social issues being addressed by the Supreme Court, reflecting its role in shaping human rights and governance in India.\\r\\n\\n\"})}),\"\\n\",n(o.p,{children:\"Well that was simple. We just created a simple agent which can search the web and return the result. But this is just the beginning. We can add more tools and make it more powerful. We can also add memory to it so that it can remember the previous interactions.\"}),\"\\n\",n(o.p,{children:\"In the next post, we will create a another abstraction on top of this like a Agent calling a Another Agent which is called a Agent.\"})]})}return{default:function(e={}){const{wrapper:t}=e.components||{};return t?n(t,{...e,children:n(_createMdxContent,{...e})}):_createMdxContent(e)}};",
    "published": true,
    "description": "A step by step guide to building your own Agent Framework.",
    "permalink": "/blog/build-your-own-agent-framework-step-by-step"
  },
  {
    "title": "Google Gemma 2B on Your Laptop: A Developer's Guide",
    "slug": "google-gemma-2B-on-your-Laptop-A-Developers-Guide",
    "date": "2024-03-06T03:30:00.000Z",
    "content": "const{Fragment:e,jsx:n,jsxs:i}=arguments[0];function _createMdxContent(o){const r={a:\"a\",h2:\"h2\",img:\"img\",li:\"li\",ol:\"ol\",p:\"p\",strong:\"strong\",ul:\"ul\",...o.components};return i(e,{children:[n(r.p,{children:\"As developers, we're always on the lookout for powerful, accessible AI models that we can run locally. Google's Gemma 2B has emerged as an exciting option, offering a balance of performance and efficiency. In this guide, we'll walk you through the process of getting Gemma 2B up and running on your laptop using Jan AI, an impressive open-source platform that's changing the game for local AI deployment.\"}),\"\\n\",n(r.h2,{id:\"why-jan-ai\",children:n(r.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#why-jan-ai\",children:\"Why Jan AI?\"})}),\"\\n\",n(r.p,{children:\"Before we dive into the setup, let's talk about why we're using Jan AI. As developers, we appreciate tools that are versatile, efficient, and easy to use. Jan AI ticks all these boxes:\"}),\"\\n\",i(r.ol,{children:[\"\\n\",i(r.li,{children:[n(r.strong,{children:\"100% Offline Operation\"}),\": Run your AI models without internet connectivity – perfect for sensitive data or offline environments.\"]}),\"\\n\",i(r.li,{children:[n(r.strong,{children:\"Universal Architecture Support\"}),\": From NVIDIA GPUs to Apple M-series chips, Jan AI has you covered.\"]}),\"\\n\",i(r.li,{children:[n(r.strong,{children:\"User-Friendly Interface\"}),\": Simplifies the process of managing and running various AI models.\"]}),\"\\n\",i(r.li,{children:[n(r.strong,{children:\"Open-Source\"}),\": Benefit from community contributions and the ability to customize as needed.\"]}),\"\\n\"]}),\"\\n\",n(r.p,{children:n(r.img,{src:\"https://github.com/janhq/jan/raw/dev/demo.gif\",alt:\"Jan AI Demo\"})}),\"\\n\",n(r.h2,{id:\"step-1-setting-up-jan-ai\",children:n(r.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#step-1-setting-up-jan-ai\",children:\"Step 1: Setting Up Jan AI\"})}),\"\\n\",n(r.p,{children:\"Getting started with Jan AI is straightforward:\"}),\"\\n\",i(r.ol,{children:[\"\\n\",i(r.li,{children:[\"Head over to \",n(r.a,{href:\"https://jan.ai/\",children:\"https://jan.ai/\"}),\".\"]}),\"\\n\",n(r.li,{children:\"Download the appropriate package for your operating system.\"}),\"\\n\",n(r.li,{children:\"Follow the installation prompts to get Jan AI set up on your machine.\"}),\"\\n\"]}),\"\\n\",n(r.p,{children:\"[Developer Note: Consider adding a screenshot of the Jan AI download page here]\"}),\"\\n\",n(r.h2,{id:\"step-2-downloading-gemma-2b\",children:n(r.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#step-2-downloading-gemma-2b\",children:\"Step 2: Downloading Gemma 2B\"})}),\"\\n\",n(r.p,{children:\"Once Jan AI is installed, it's time to get our hands on Gemma 2B:\"}),\"\\n\",i(r.ol,{children:[\"\\n\",i(r.li,{children:[\"\\n\",n(r.p,{children:'Launch Jan AI and navigate to the \"Explore\" section.'}),\"\\n\"]}),\"\\n\",i(r.li,{children:[\"\\n\",n(r.p,{children:'Use the search function to find \"Gemma 2B\".'}),\"\\n\"]}),\"\\n\",i(r.li,{children:[\"\\n\",n(r.p,{children:\"Before you hit that download button, take note of the system compatibility information Jan AI provides:\"}),\"\\n\",i(r.ul,{children:[\"\\n\",i(r.li,{children:[n(r.strong,{children:\"File Size\"}),\": Crucial for managing your storage.\"]}),\"\\n\",i(r.li,{children:[n(r.strong,{children:\"Performance Indicators\"}),\": Jan AI will let you know if the model might run slowly on your device.\"]}),\"\\n\",i(r.li,{children:[n(r.strong,{children:\"RAM Requirements\"}),\": Ensure your system has enough memory to handle the model.\"]}),\"\\n\"]}),\"\\n\"]}),\"\\n\"]}),\"\\n\",n(r.p,{children:n(r.img,{src:\"/static/Screenshot-28a3cc2c.jpg\",alt:\"Jan AI Model Compatibility Screenshot\"})}),\"\\n\",i(r.ol,{start:\"4\",children:[\"\\n\",n(r.li,{children:\"If your system meets the requirements, go ahead and download Gemma 2B.\"}),\"\\n\"]}),\"\\n\",n(r.h2,{id:\"step-3-running-gemma-2b\",children:n(r.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#step-3-running-gemma-2b\",children:\"Step 3: Running Gemma 2B\"})}),\"\\n\",n(r.p,{children:\"Now for the moment of truth – running Gemma 2B:\"}),\"\\n\",i(r.ol,{children:[\"\\n\",n(r.li,{children:'In Jan AI, click on the \"Chat\" section.'}),\"\\n\",n(r.li,{children:\"Look for the model selection dropdown.\"}),\"\\n\",n(r.li,{children:'Choose \"Gemma 2B\" from the list.'}),\"\\n\",n(r.li,{children:\"Start chatting! Your local instance of Gemma 2B is now ready to process your prompts.\"}),\"\\n\"]}),\"\\n\",n(r.h2,{id:\"developer-insights\",children:n(r.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#developer-insights\",children:\"Developer Insights\"})}),\"\\n\",n(r.p,{children:\"As you start working with Gemma 2B, keep these tips in mind:\"}),\"\\n\",i(r.ol,{children:[\"\\n\",i(r.li,{children:[\"\\n\",i(r.p,{children:[n(r.strong,{children:\"Prompt Engineering\"}),\": Gemma 2B, like all language models, responds best to clear, well-structured prompts. Experiment with different phrasings to optimize your results.\"]}),\"\\n\"]}),\"\\n\",i(r.li,{children:[\"\\n\",i(r.p,{children:[n(r.strong,{children:\"Performance Tuning\"}),\": If you're running on a less powerful machine, consider tweaking Jan AI's settings for better performance. Look for options to adjust the model's precision or inference settings.\"]}),\"\\n\"]}),\"\\n\",i(r.li,{children:[\"\\n\",i(r.p,{children:[n(r.strong,{children:\"Offline Capabilities\"}),\": Leverage Gemma 2B's offline nature for projects involving sensitive data or for developing apps that need to function without internet connectivity.\"]}),\"\\n\"]}),\"\\n\",i(r.li,{children:[\"\\n\",i(r.p,{children:[n(r.strong,{children:\"API Integration\"}),\": While we've focused on the chat interface, explore Jan AI's API options to integrate Gemma 2B into your applications programmatically.\"]}),\"\\n\"]}),\"\\n\",i(r.li,{children:[\"\\n\",i(r.p,{children:[n(r.strong,{children:\"Model Comparison\"}),\": Jan AI makes it easy to switch between models. Consider comparing Gemma 2B's performance with other models for your specific use cases.\"]}),\"\\n\"]}),\"\\n\"]}),\"\\n\",n(r.h2,{id:\"conclusion\",children:n(r.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#conclusion\",children:\"Conclusion\"})}),\"\\n\",n(r.p,{children:\"Running Google Gemma 2B locally with Jan AI opens up a world of possibilities for developers. Whether you're building the next revolutionary chatbot, working on NLP projects, or simply exploring the capabilities of AI, this setup provides a powerful, flexible foundation.\"}),\"\\n\",n(r.p,{children:\"Remember, the field of AI is rapidly evolving. Keep an eye on Jan AI's updates and the broader AI community for new models and features that could enhance your development workflow.\"}),\"\\n\",n(r.p,{children:\"Happy coding, and enjoy exploring the capabilities of Gemma 2B right on your laptop!\"})]})}return{default:function(e={}){const{wrapper:i}=e.components||{};return i?n(i,{...e,children:n(_createMdxContent,{...e})}):_createMdxContent(e)}};",
    "published": true,
    "description": "Learn how to run Google's Gemma 2B AI model locally on your laptop using Jan AI, opening up new possibilities for offline AI development and experimentation.",
    "permalink": "/blog/google-gemma-2B-on-your-Laptop-A-Developers-Guide"
  }
]